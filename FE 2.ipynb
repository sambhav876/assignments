{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed72498-8d4d-44fb-b5f5-26a84863e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 1\n",
    "\n",
    "#Min-Max scaling, also known as normalization, is a data preprocessing technique used to transform numerical features of a dataset to a specific range. The goal is to scale the values of the features in a way that they fall within a defined interval, usually between 0 and 1. This is particularly useful when working with machine learning algorithms that are sensitive to the scale of input features, such as gradient-based optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c7323-bd9f-47e6-9800-b90e495f8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 2\n",
    "\n",
    "\n",
    "#The Unit Vector technique, also known as vector normalization or unit normalization, is a feature scaling method that scales the values of a feature to create a unit vector. In this context, a unit vector is a vector with a length of 1. The idea is to scale the values of a feature while maintaining the direction of the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce1b7e4-4366-430a-b7c5-1441b8b630d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 3\n",
    "\n",
    "#Principal Component Analysis (PCA) is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional form while retaining as much variance as possible. The primary goal of PCA is to identify the principal components, which are linear combinations of the original features that capture the maximum variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37509d9d-2be1-43b8-975d-9231c4aab2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 4\n",
    "\n",
    "#\n",
    "PCA #(Principal Component Analysis) is a dimensionality reduction technique, and feature extraction is one of the key applications of PCA. In the context of PCA, feature extraction refers to the process of transforming the original features of a dataset into a new set of features (principal components) that capture the most significant information or variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347eaa6f-d392-402e-93d3-de48c60fc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 5\n",
    "\n",
    "#In the context of building a recommendation system for a food delivery service, Min-Max scaling can be used to preprocess the data, specifically for features like price, rating, and delivery time. Min-Max scaling ensures that these features are on a similar scale, preventing one feature from dominating the others due to differences in their magnitude. Here's a step-by-step explanation of how Min-Max scaling can be applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175afb09-6fe2-4c30-8d81-efbabca214f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 6\n",
    "\n",
    "#When working on a project to predict stock prices with a dataset containing numerous features, PCA (Principal Component Analysis) can be a valuable technique for dimensionality reduction. Reducing the dimensionality of the dataset can help mitigate the curse of dimensionality, enhance computational efficiency, and potentially improve the model's generalization performance.\n",
    "#Data Preprocessing, apply PCA, New Feature Representation, Model Building, Interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb97bc5-d0f7-44c2-a242-e1c3e66def27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 8\n",
    "\n",
    "#The decision on how many principal components to retain in PCA involves finding a balance between preserving a sufficient amount of variance in the data and reducing the dimensionality. One common approach is to examine the cumulative explained variance, which helps determine how much of the total variance is retained as a function of the number of principal components.\n",
    "#Standardize the Data, apply PCA, Calculate Cumulative Explained Variance, Plot Cumulative Explained Variance, Choose the Number of Principal Components, Interpretability and Application Needs, Reapply PCA with Chosen Components."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
